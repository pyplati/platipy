# Copyright 2021 University of New South Wales, University of Sydney, Ingham Institute

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import os
import tempfile
import json
import logging

from pathlib import Path
import SimpleITK as sitk
import numpy as np
from scipy.optimize import linear_sum_assignment

import comet_ml  # pylint: disable=unused-import
from pytorch_lightning.loggers import CometLogger
from torchmetrics import JaccardIndex
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint

from argparse import ArgumentParser

import matplotlib.pyplot as plt

from platipy.imaging.cnn.prob_unet import ProbabilisticUnet
from platipy.imaging.cnn.hierarchical_prob_unet import HierarchicalProbabilisticUnet
from platipy.imaging.cnn.unet import l2_regularisation
from platipy.imaging.cnn.dataload import UNetDataModule
from platipy.imaging.cnn.dataset import crop_img_using_localise_model
from platipy.imaging.cnn.utils import preprocess_image, postprocess_mask, get_metrics

from platipy.imaging import ImageVisualiser
from platipy.imaging.label.utils import get_com, get_union_mask, get_intersection_mask


import random
import math
from pathlib import Path

import torch

import pytorch_lightning as pl

from platipy.imaging.cnn.lidc_dataset import LIDCDataset
from platipy.imaging.cnn.sampler import ObserverSampler

logger = logging.getLogger(__name__)

LIDC_PAT_IDS = [
 '100036212881370097961774473021',
 '100063870746088919758706456900',
 '100196544861967692255437311943',
 '100623635004206394377317082803',
 '101324598070011890446155612648',
 '101370605276577556143013894866',
 '101493103577576219860121359500',
 '101860660338020663891435526309',
 '102630309685058068986252460648',
 '102727149680558741079248783846',
 '103314508209751760357909975504',
 '103418693958392288272205189260',
 '103909846248671377349144781232',
 '103936837659251066416686642502',
 '104132635304747270459442606987',
 '104261792177613018096518227983',
 '105788018052982730868269746567',
 '106068656437895419353734796481',
 '106078428010894478241933303675',
 '106200285452190102759452314796',
 '106510194697877936244358836587',
 '106941897938005462856300775001',
 '107063920355575867343721608071',
 '107117680739311641559517949056',
 '107410301078591208486461903808',
 '107508721613473648848595116695',
 '107781084804242272261405060893',
 '108196413521053893318500192469',
 '108532092918956660012164380891',
 '108965194825990605371103747168',
 '109276391800556245215148059611',
 '109666061122737469139155049085',
 '109666408795826210278851151448',
 '110552610218214013901193645855',
 '110583593061096148970283270811',
 '110814261083396253384916416499',
 '111191540532827735098734161238',
 '111578894836113526186151044207',
 '111854046978561013667340276013',
 '112366982107658327153398402250',
 '112657410053794387237858900758',
 '113336731083882049431478817978',
 '113559330012918930951543504919',
 '113703017711510899918035270531',
 '113707792304333965399737722872',
 '114128037878340599989460011716',
 '114825706723542293203506302449',
 '115235596345340852495791642145',
 '115862643355747092400544598419',
 '116398718009259533261076124801',
 '117534698898058162410044712500',
 '117743534419290251609867537261',
 '117809518219141943884237457410',
 '118873832573622894386164980989',
 '119160670718020063800771208605',
 '119329123269319944171115250782',
 '120580422725898456426920474122',
 '120781932093240979642841947845',
 '120891719798974864125658202102',
 '121477207174726219407790693667',
 '123305427042753000123559340989',
 '123740919388465597562183738584',
 '123757952382514314958340753104',
 '123906098414077028808869184162',
 '124043676181995670004300402875',
 '124508094927772723365648607398',
 '124918015490899130716961145499',
 '125091393024330590664846028519',
 '125196609469610531868822891452',
 '125755525194735914218741665527',
 '125968645555307955291497942287',
 '126579974603592904802118981222',
 '126627335783756807832314347589',
 '127299727722058129007613721740',
 '127335250316932247803669656678',
 '127418142282097214960207117703',
 '128173929531863533946053948407',
 '128331462267861650186674238297',
 '128546361353633775045659990592',
 '128707571431497524813677196205',
 '128882236014679059490275573019',
 '129172271455973626256608772850',
 '129889229961080005326707611943',
 '129896477022915871974945777250',
 '130212238381185558806293057208',
 '130369694349415652282198282842',
 '131383203689189807643685075952',
 '131386286964058684099078579332',
 '131639774933066433859447191174',
 '132644395812981309476663139204',
 '133142523452166818708847170969',
 '134300369034461601145053122049',
 '135015991565946540622375616104',
 '135045503670480596826162811572',
 '135295547724563274783029730811',
 '135354380632609557236443907760',
 '135441977655501389639333579222',
 '135649280843401063699693855484',
 '135664533107982155600588797111',
 '136876570107341293094375256847',
 '136980005417322283801813327480',
 '137094437164923904545127071746',
 '137641101085876511008939491396',
 '137750025318220725626773657356',
 '138141860630920227890886912798',
 '138500869556929311152852869529',
 '138662618939201961985267634802',
 '138751917514248782010778675083',
 '139007379520761595657549251638',
 '139110171863263699469684411692',
 '139195294068636036088709372879',
 '139230809749319928621494922594',
 '139267808951641148096439810470',
 '140032007657380601732641072716',
 '140071422310372235469229806680',
 '140459664666732545368292166616',
 '141598007834192132861466794478',
 '141781718363585577687281036482',
 '142292437379762052008677682241',
 '142440312470956325774436777849',
 '142946965450964505637435479607',
 '143147006327116114851951568235',
 '143774983852765282237869625332',
 '143992300791476122502099615811',
 '144067942028925306269987156361',
 '144098736774350495825430776051',
 '144115995771389118102515965956',
 '145101705103753228347955694208',
 '145271800733926000322166019837',
 '145309426008342216455171944681',
 '145373944605191222309393681361',
 '145622720063142155634645333747',
 '145643207559809787753499447041',
 '145676616748203729170191829666',
 '145713291593525654962776610448',
 '146389062541391302265553091834',
 '146673599499822520893810766696',
 '146693794897525614810620472732',
 '146874505599848236392134956519',
 '147007934469588183141400115665',
 '147078385001386003318643105546',
 '147369388209402780868232397204',
 '147379540710364690031394735651',
 '147528196931888636188830549231',
 '147704659627178252268482840005',
 '147733809306552412615241520287',
 '148358074732977192643732679421',
 '149109655051916227035843294920',
 '149666752178793201786367154542',
 '150115359973664720902580965129',
 '150164970015823494629986891791',
 '150188222462440903489565305064',
 '150264634200093580367988090366',
 '150506552813421138982733853172',
 '150518738304733101418007977406',
 '150842260481112310322112796796',
 '151462193009815033155890307894',
 '153537389944109506778485451374',
 '153879314331255637907074508526',
 '154013297600241321274325492714',
 '154309317539716408682560573374',
 '154418190532000744482160157724',
 '154819036420703297447036427861',
 '154900488526447142456824787975',
 '155364374491657276710118621544',
 '155422883755338970256390193392',
 '155557195003938299459901738073',
 '155894685355411131558273211903',
 '156049232240708034287535871530',
 '156618458422978822822335971869',
 '156996082231474939899578263697',
 '157442654089163434314265938550',
 '157659992364948575945704799673',
 '157894141428308694229687552009',
 '158361076621595636405240935776',
 '158967312129487733823739945169',
 '159154526664736300420420966290',
 '159596875781736451820677432740',
 '160151929696133590075333292104',
 '160177241792963961453620813854',
 '160725905583575318613483772884',
 '160881090830720390023167668360',
 '161049972809841608349356015239',
 '161084022770774658371336888233',
 '163285696979961262813032969899',
 '163364452480273959392764002225',
 '163747591665714002593484708741',
 '164156833754689412076055510609',
 '164204559177081679885683922807',
 '164217405113124054884377740544',
 '165017330457520545748655969705',
 '165089822985195173225904535454',
 '165584568388616938096482975079',
 '165741627456266454825445080793',
 '165928214371593461789742284562',
 '166043246571762775528650569121',
 '166045097359941678759735162107',
 '166516471529644578497840692226',
 '167008253410339916258991990447',
 '167332257805620834964807748714',
 '167385525980664447633063747843',
 '167461514102912667251280826923',
 '167481427179213606474786125326',
 '167583044843097027161721296977',
 '168697575496383193075236640012',
 '168750903689425205479060653325',
 '170453435914624225750000821602',
 '172057344391312701982079788940',
 '172781764368509306119706213242',
 '172879081603366631101823390088',
 '172891325013037275999502688439',
 '173046050032662152275088620852',
 '173476782913985657859750913739',
 '173480979711457247360986415860',
 '174771861434175096253509271253',
 '174809695196160918760894715771',
 '175760080411828194592094064838',
 '176119253416372337672619835088',
 '176189447010290638749878151482',
 '176724808324080338407584179625',
 '178008579082565292854358918057',
 '178054575127307086914328123377',
 '178055839088630125000227320316',
 '178854189219941544047372620516',
 '179835446111622550556046150972',
 '179926192573878616596153758496',
 '180089742036563526934101223693',
 '180451931053147153984482896172',
 '180685600263085599637486877417',
 '180841215015376467807831976209',
 '181183885950568332347816930781',
 '181398349112343043834924846577',
 '181417885049753012096413476972',
 '181593981812293966599842811096',
 '181785797305004428693015149455',
 '182110250999021699484937823450',
 '182190805623310236601030915541',
 '182529561822199780545440408033',
 '183088557662694130014178072362',
 '183948389971742539190611659002',
 '184902022874872369505485150214',
 '185466477130333115741807427373',
 '185496461202477950899792771158',
 '185621295429000591339779532687',
 '185810436275168701789786930141',
 '185852472264155752604841654643',
 '186165274648953680758061039841',
 '186309477398566417518475261664',
 '186378343509510052901886052675',
 '186545761857837015081715243889',
 '187400292293901990471724598227',
 '188204058669364993757306038569',
 '189280790286095758626785941529',
 '189670740451073875347541923169',
 '189690798782956693829000203312',
 '190036064555105762519342089670',
 '190045142764457963256735097041',
 '190188259083742759886805142125',
 '190578678221433604759795450204',
 '190722769298607626547238572819',
 '190773468090009472439928213592',
 '190838841811080874400532510738',
 '191073955214402396197702655759',
 '191294111388782437161651532011',
 '191417614594472789714997861946',
 '191425307197546732281885591780',
 '192544770425703459348950670623',
 '192711002126941665635416825711',
 '193183513859852492693631043956',
 '193241055656414949090207821605',
 '193262972800234484744399468745',
 '193438875802960011844317570223',
 '193632643404878480165927810858',
 '194041219679835518833081477370',
 '194069107440754900812783343110',
 '194264995369749234588783691976',
 '194408227371077105112329346518',
 '194592222324100678493470529736',
 '194890498394311571938776742465',
 '194989275190883931437102127157',
 '195049537858207829551926654069',
 '195418537319448622946575911056',
 '195536973222079080038674523383',
 '195975724868929317649402600442',
 '196064403160663787222867039271',
 '196095989034530030261387979708',
 '196764647858692982718767974745',
 '198021313421875017435046583973',
 '198480745206106280149820227940',
 '198938890575750893735876189224',
 '199795594928180609213453658461',
 '200080981983036698023153287807',
 '200388868639180278429905174768',
 '200556866344536431817884531386',
 '201356741575321997579793754679',
 '201981314170126152586920703158',
 '202012743926377385386645171009',
 '202087967488314629195929644257',
 '202128825827009854792580489975',
 '202313610740309364769212928365',
 '202796045319384029259715575526',
 '202827697628802454715911097315',
 '202972199430488069905719748096',
 '203021212653448281775262541232',
 '203511118110447056499830468108',
 '203745372924354240670222118382',
 '203918583798186026281890202047',
 '204167514516464519480528962273',
 '204769919102665056662271574089',
 '204876032380829136260582432402',
 '205265707007087091421912273273',
 '205295494158831463556858756520',
 '207817820000493988193034888372',
 '208001565962486054565606721023',
 '208044717702980576765085373999',
 '208177797605474151106520124306',
 '208253527688434910178787865281',
 '208376669554572460085205852204',
 '208962973581011466719041210639',
 '209628614952351211282586434983',
 '210105060472758363785916556991',
 '210438744022591353484036052860',
 '210460865401632134346677582159',
 '211028058202430803930155553655',
 '211053720209798423692283723094',
 '211186311281767598090156083844',
 '211592828197214585826096300114',
 '211678183477028942594541249344',
 '212173791575971142588528365479',
 '212292046142156223429795319169',
 '212341120080087350703610584139',
 '212697393127299815450339637649',
 '212995606100714447928555271551',
 '213021056957630403662329810457',
 '213021675581421639588001132423',
 '213637791937214112275825554647',
 '213690221459882536855619399918',
 '213735911041216674787295333807',
 '213747445868893344159976127183',
 '214011375577453036409274126845',
 '214246516675840948112237158320',
 '214565862082106444257760478581',
 '214802309639542154012576451584',
 '215072449579869595247908643994',
 '215530681893783493990923094397',
 '215559453287121684893831546044',
 '215789618966985272514045108451',
 '216284625800598617220647330177',
 '216376032357092323639269932442',
 '216596541995300108433152752372',
 '217723017594466509330246364292',
 '217795632219483181846615097960',
 '218334290952989306683953951600',
 '218353171044902873293532449170',
 '218441204865582835284481030822',
 '218658642102832118810712329678',
 '219081768759399413645906161308',
 '219248583669253502298142724766',
 '219603183011909533511019563626',
 '220214273010365852692388401870',
 '220250766483775468847898872976',
 '220318312497776009932500036468',
 '220440176952423273988539874706',
 '220989155161038735570528881205',
 '221121159879001927899714055324',
 '221138977753587043062153841454',
 '221467562933372960599414594591',
 '222363923835851360513495795866',
 '222444895275634974977432374937',
 '222626438572167217610357947558',
 '222993894345836169253703951249',
 '223586178787100112140685204730',
 '223728112116674740171130784710',
 '223929343925645778515146916755',
 '224816556084824998460890400016',
 '224985459390356936417021464571',
 '225213110794629789874295007045',
 '225325726732923728196849027710',
 '225336514441526266989689082116',
 '225520892751936930714518753705',
 '225862377550650653917701158715',
 '225952820864846070881460157728',
 '226088449233409636933226805676',
 '226402817998131997261275093738',
 '226719444846209417020566423366',
 '227040504303112430978662427134',
 '227063200244152860572015411033',
 '228681789686851016136117645559',
 '229037285595999197108233114060',
 '229388260375062685257395968125',
 '229453814067948782185747812606',
 '229800514909823088973473373045',
 '229967962418363878052269915938',
 '230350651484561219081974325611',
 '230800355892152356700875480882',
 '230901123329037029807195618747',
 '231462296937187240061810311146',
 '232333503337684976076888189581',
 '232484282311807761778575987163',
 '232772963487864165109888489609',
 '233185200895881555317060584785',
 '233265558039230075858412321938',
 '233360976397162618015897824056',
 '233972273372473359632172336060',
 '234120235997503955698755550667',
 '234289514191030145998276287188',
 '234418158081986309761071794125',
 '234565379252678413221170803425',
 '234994879536134968838889803884',
 '235161199041083161581467190209',
 '235632691141320250472721126959',
 '235969059582659051462660101595',
 '236473827829552232243074977782',
 '236694495816915149507620783797',
 '236722533610330821341378792527',
 '239129180722773562585191194111',
 '240259014486900472744222753388',
 '240378069135678893749859521194',
 '241438921576606444541425654823',
 '241689052849438260084754220656',
 '241863405068914130326466911331',
 '242293704887164773216756108679',
 '242682647435854260754234965628',
 '243200997268477396967173500055',
 '244389108887315437307204657105',
 '244560540649171231768816505483',
 '245332552721136420493204351294',
 '246309121384607847712377186777',
 '246541809203697037171004327898',
 '246917032284352184215612201998',
 '247360966390848191713625967090',
 '247647652518040926954657385575',
 '247813601128055334769770235073',
 '248466778281073632010340585979',
 '248536440095859239568984753729',
 '248655117969906530264763921998',
 '248983002956469734140739709749',
 '249778071616205114955151949358',
 '250118712805848631355370259962',
 '250770014904528873190814943829',
 '250807847445096579567542381073',
 '252510005003229547978208913780',
 '252807379241747927058486908845',
 '253018306736883838620886843861',
 '253123637959400428278268237946',
 '253735246078920128978742275635',
 '254284452408440744726985192393',
 '254597093814481056655048098352',
 '254734404186354295325724812720',
 '255547294378103412654877543117',
 '255763746952382642554143442493',
 '255996783379921037765414923334',
 '256230432050930445318439765836',
 '256415982022395230813284649190',
 '257497390857480311387964520553',
 '259516711483314195853998851316',
 '259564082580389615261241066925',
 '260157243922037600449005570857',
 '260650317266630055112768212364',
 '261049959740626621730647171520',
 '261859010096419762853634942928',
 '261881453527700554965645624212',
 '261896829953142370809123984374',
 '262233919583075373552810415567',
 '262372993180687488521371393069',
 '262595324886254011362748468025',
 '262752628257670445166772606344',
 '262940731886389902640730271210',
 '263031755598034095800749048602',
 '263062819617890562693932243280',
 '264122020925099449244490627864',
 '264393460861616413192668347002',
 '265116643168672454267341689554',
 '265390640843728236501931252310',
 '265657827498396379702226874113',
 '265704884949271879044145982159',
 '267013157670921984098319605661',
 '267153963553416618872924015484',
 '267214856456387865154306936080',
 '267354935124724968585540389507',
 '267430321455341154577885873460',
 '267495169884268604035801498197',
 '267607850463096817515575285607',
 '267745911637906357699108280139',
 '268186928222507173063266624020',
 '268490252284941048496256182524',
 '269532656350104249022826895294',
 '269549495557169661890212203300',
 '269815821605052946328618031845',
 '269884215256755446329937557120',
 '270093416536223137275197282336',
 '270449468111534490183179612522',
 '271910441918529291689264844963',
 '271916801059080642953570118476',
 '272102141116238598947111407982',
 '272416900158314679872946504460',
 '272747692608963634087245721224',
 '272800023895682200488000769712',
 '273398739486305201304583240983',
 '273873499396396267864941267496',
 '274533538808543280646156261676',
 '274709137328120797052487052456',
 '275166955484270759335764642842',
 '275342292592333052340429698533',
 '275399413024322303306387851279',
 '275597169013178714160720614233',
 '275892948066257709459536915546',
 '276145303905683401700212326794',
 '276357014804464864262939025676',
 '276910031320955223579056176086',
 '277707646521145217625235879315',
 '277917899093238118799634234844',
 '278314508776467367928735781601',
 '278388415999131655907385534718',
 '278420383577925795821592801973',
 '278571116570364233687639963534',
 '279133908903915300821612602665',
 '279133997079513544257388158962',
 '279815994089337890330418719400',
 '279896786227805041031596230124',
 '279957551156089498592959292779',
 '279988868485323680600035963215',
 '280050083021766496264016832213',
 '280315210397549164238230581781',
 '280531413986295071283803322793',
 '280944743442493595294591879190',
 '280963839031344532519735389631',
 '281149709266012657212003921035',
 '281491059962512876018428810934',
 '281499745765120562304307889347',
 '282376078213521832826757169162',
 '282592678243385281753684471720',
 '283065772077726118787509535476',
 '283314504686117114905176791940',
 '283363009241515390315316302638',
 '283388878260039881020061501616',
 '283747814329309197645868691560',
 '284028192986684647771628933377',
 '284088385995679184706750192135',
 '284091129290542528109405627934',
 '286257039861864871390665013995',
 '286786177811953810051065476115',
 '287560874054243719452635194040',
 '288142673190348607009892502290',
 '288625283139929827339044364850',
 '288836300158326561947306862905',
 '289084067435838460184299744241',
 '289145216356920254799922475037',
 '289514702605693988808674635347',
 '289759534306508848209269388603',
 '289886930576192132696568423166',
 '290602873613899406112457532639',
 '291105837361929821655470189849',
 '291351987478858068691768357060',
 '291817048149111149961802063949',
 '291896014000911872483739610441',
 '292207153428070172322351824035',
 '292226263060859572730824828126',
 '292267299840811335940503268889',
 '292294220516976158142911380662',
 '292417350644573735869959859895',
 '292628672046109312619048073568',
 '293433201388001070931182667378',
 '293760350481778481843102622378',
 '294168619890384187906139486190',
 '294653264607473621174579354155',
 '295517876835894730236647974030',
 '297192539691487434404158853083',
 '297491710261529399075427138612',
 '297522203193490519910431870739',
 '297927758886508342527732573281',
 '298180121619674780553933016732',
 '298731156484751583249477309475',
 '298806137288633453246975630178',
 '299122687641741853427119259207',
 '299257181285137013436464151874',
 '299799877133044736642536495362',
 '300409677036863686976674785893',
 '300568323537528705778699437287',
 '300829918445389512656506955074',
 '301465695265899538081208550111',
 '301771434938229546704232023262',
 '301893285809694674511225349300',
 '302256916113808751290358737152',
 '302506223349239046044276337140',
 '302617159747584825959135390069',
 '303099231937480740934110243375',
 '303241414168367763244410429787',
 '303407883137142435506738687070',
 '303408504856716615682692778690',
 '303856284614793157222299489373',
 '303921580531000844896433537490',
 '303924616208074142487120966776',
 '304088547901303960997044129270',
 '304128927772479718113589870111',
 '305011216002720504189976406136',
 '305196230708291505432654379176',
 '305234403531996676303325051420',
 '305703349227966644337102413678',
 '305756441152306462678795884038',
 '305863253247137744276642948253',
 '305942859345281883515236698139',
 '306209107793490820623279780488',
 '306223432026099623241869333271',
 '307585785421640145685948300552',
 '308816704145697573874568073799',
 '309118579255866880117522688599',
 '309564852246680613688744241427',
 '310090830439147530838142668838',
 '310500752247645337767427178242',
 '310641973458012698326158285915',
 '310869628943317589181434675447',
 '310943546307547399461310181653',
 '311286315716340154235274558813',
 '311453461766047239391876458979',
 '311543823141683719978679431015',
 '311849240521371267537044867782',
 '311959464221077415127494283158',
 '313434017581738347830026996031',
 '313935464622070730633776692194',
 '314071149857693870088107222867',
 '314119990938826728339463484244',
 '314138616411061948052843767346',
 '314166198948235683770741486536',
 '314311311148468433820105763522',
 '315896257598312492181693323227',
 '316049072680605749900519988649',
 '316334611043225263064716257742',
 '316733915710399203923795639422',
 '317269195393986070164185617972',
 '317273043933560935570616831007',
 '317889411189319524523491450294',
 '318162998398046037585497173804',
 '318267749315379295095253644829',
 '318387528257740161829281579408',
 '319426861743264377998637994320',
 '319437016886652687834302851680',
 '319457039993091948420654822534',
 '320868967976297780563487478878',
 '321085339464682432111441689315',
 '322060710223427694979493449810',
 '322126192251489550021873181090',
 '322524653283033873625769278172',
 '322604336063659838243542603396',
 '322613172334101771105940174946',
 '322995703216827528672839235412',
 '323012452641612668480978720171',
 '323769537371782501749772855211',
 '324291021807344718518738544991',
 '324680252006411183918098592500',
 '324827271082263044582582668595',
 '324984193116544130562864675468',
 '325608968275343627520297346991',
 '325830590463177737667102135732',
 '326240009912333401253143950265',
 '326258759789625717227327619747',
 '326975664298894323901926187239',
 '327389263896737471496228866506',
 '327833349640691088534060439127',
 '328557408996437290097300166360',
 '328985441791613247896558648523',
 '329219900591912979945974892373',
 '329360542712571362247573112426',
 '329498168249206597932161726910',
 '329613415894061309409362825998',
 '330311286390409730062500041756',
 '330694158626612266669807704245',
 '330786107789886395527713704821',
 '331662654015358587276208254750',
 '331912290213688157146431129496',
 '332442253024965725100180832377',
 '333224958421615824054029320306',
 '333362756208643390458434024958',
 '333911857799694588686208472307',
 '334142682219743556615674397992',
 '334404540722450737157825443529',
 '335511385175207746688439743644',
 '335945989892274983962989644650',
 '336137933660116977458622909107',
 '336271942450113106996588030279',
 '337712862699308652663458299448',
 '338336992240867140131763172276',
 '338445093314190310902086699869',
 '338681063148697211042842329869',
 '339170810277323131167631068432',
 '339555666338359721401666777459',
 '339975625902908481435949410827',
 '349215784927595126067491535375',
 '349904517868103143773797132680',
 '359494088606212053886005767834',
 '361004729625204263297457202086',
 '370700630609225608130630902041',
 '371593558888147552115426364555',
 '373342454335320815569534817014',
 '377835929784075736831041456357',
 '378894347946872778030844834278',
 '382216295557686059503096506837',
 '385976057629453563236462196337',
 '389796291341364059012825103262',
 '392974922683023240281753530297',
 '402240049299350560004923763412',
 '403432615973617823449253024665',
 '407122010994373607607380330242',
 '419136021853948294349111583097',
 '426292960722746490523326036933',
 '427346572209935588501414358601',
 '428749210060996400535779285747',
 '429699865856208366565779600254',
 '434247094534802729512368079584',
 '434847191991072856104231378329',
 '437063545936574671385154679589',
 '440475654600005860316686606177',
 '442836465012574652961690947717',
 '443753256239015192514766534461',
 '446141203915389353091048690870',
 '456657617221039306684558366650',
 '461502489756528153281751961352',
 '467953176348008114522042094789',
 '471106432014627176550866096857',
 '473852308535992451018178219915',
 '475498514082515864100304794963',
 '477738775879476870029318616682',
 '481620140149228611720235499832',
 '490157381160200744295382098329',
 '495416793311762759653372975706',
 '498311492348035259054610823788',
 '503842574668180938785276053000',
 '508213936241272779545636798976',
 '514061889253028999256401521179',
 '518232152391739792448041571173',
 '520374343116562553369175888897',
 '520765263344096922537272606423',
 '521368364741046707593021144453',
 '522940913934103637427459195079',
 '530012655070930408996523309860',
 '531322615015231731672909400685',
 '534939840290931669471335109271',
 '541564533926823186990087847268',
 '542174473570958426088104535645',
 '547848375366758290042983535032',
 '553558667874341556649497579315',
 '554408346761971894109361624151',
 '554779663962875550258283150632',
 '558678722336494515704990369281',
 '559695947493996195628793160329',
 '559812581756025353887436599032',
 '560355181698089203099323359955',
 '561164700626233888666112673613',
 '562420213730031312300572553711',
 '563554930011057425448972918752',
 '567798120866426088049494542765',
 '568590496455752271550307195037',
 '573428694448853086196304337865',
 '577239032421661596436882763701',
 '579308169960338143353751288115',
 '584233139051825667176600857752',
 '593684538737645231443136404239',
 '598304550863987021597036432704',
 '605832828213886887633700370869',
 '607604221900107393271004692863',
 '612557072934890742784673621068',
 '614525372854817919294823651430',
 '617121763259379501895075067753',
 '618131472311494996047749006675',
 '618911015325871816381733899879',
 '622768579679891665663217992331',
 '626070671580164939197414981549',
 '633670303116637733124704376946',
 '635629010879455042713206694910',
 '636909670997007752324450926079',
 '637798773907788996937534925551',
 '639539378810400142491972900031',
 '651527937137773549514457517157',
 '657015929286431430594491075660',
 '660741147026674947967595590708',
 '662868666186676193600672178489',
 '663171561625683396375993994291',
 '669072071991651987864331187685',
 '670416970629038619301651972112',
 '670760254175238186822024748574',
 '676549258486738448212921834668',
 '679317079042102339180690634322',
 '684533679602381775258237049962',
 '684596493379395503904158873210',
 '690051876029508763760267564639',
 '691546855561342606351412524861',
 '694111741408084165729604375833',
 '694589790483267758352592215517',
 '701448858177597192177075232452',
 '704695217041193188031506800434',
 '708247959534230054025514993152',
 '709632041446581971088663252665',
 '709632090821449989953075380168',
 '709924281509506265799179464374',
 '713948008609685722859788330157',
 '716587475529555681439302477222',
 '719888539703313386206966716806',
 '721161755719965069770622927051',
 '726410718508119500341020689167',
 '728284743932342406301468721019',
 '731392422930133359505662856851',
 '732422099119935556160069769037',
 '733596311057474916459070445858',
 '742963139611542313018036607058',
 '744833949134301384249366916145',
 '748854471032735053174016711473',
 '751341984016651692739143511794',
 '751804495161511023323654179121',
 '752603750437458841409277737148',
 '760852670133552234806401724338',
 '765927507488089285529132136179',
 '765963830187381205722436255156',
 '774224171618605001583693363297',
 '774862199189105930723757496082',
 '777672393907254490640128410455',
 '780121538270617222115253441513',
 '783812685850339917048882413972',
 '788972240715000723677133060452',
 '793828050288475038053022222683',
 '803342036141517365362713834879',
 '807635771657676107005923650811',
 '807847494300907496059830326562',
 '808134164613518601297092139901',
 '815399168774050638734383723372',
 '818004751275342069818453790263',
 '823962363630113925122585468962',
 '826821417415213438164503950143',
 '837252783245693412667023877670',
 '837260510399523070637863582641',
 '837471965665975230389385298092',
 '843094005962961412710063697075',
 '847046315234934266835024451770',
 '848745302315101424036793123771',
 '849069697860879761549990488101',
 '849090059968404135199482374496',
 '849666522017598388280673804221',
 '850568285181410483219385441815',
 '858300670101158401140123918818',
 '859733375254493048647590696534',
 '867436015578673140421767840022',
 '871736676471446897375109464440',
 '879950425588844557177426831791',
 '880369233375230345237001511006',
 '886180838786633773936677813818',
 '886430358468567310311007723004',
 '887916493746193939407481623391',
 '888021904600511420323095129935',
 '888517498954149177086283916722',
 '891182989185983545761655978623',
 '897705953598294772269569489281',
 '899082900417573006084750602123',
 '899353684702041035700102438716',
 '901103510796290218917651903823',
 '902763751470786794946912471631',
 '906824386019316813789030483695',
 '908741193082513651836950434578',
 '911801947447849749468305764840',
 '915736860556289509455669530049',
 '915986308688735366393353350740',
 '919002813906622793381125049416',
 '921287276013810837359841315530',
 '924939006160714533549353726515',
 '925679448263116681180549137562',
 '927075281189608119735911336961',
 '931660023131522836511470299550',
 '934701751347399243333120058853',
 '939103340398727679812199945201',
 '952440288393343800284327753087',
 '965523656856760127560055059644',
 '969325292841504805778529336047',
 '971476961920773226447199844576',
 '988068515766013782236551550185',
 '989440509183467842001314342301',
 '995561512722026805270815340218',
 '998144378008088787705870980497'
]

#LIDC_PAT_IDS = [
#    "208177797605474151106520124306",
#    "234289514191030145998276287188",
#    "255763746952382642554143442493",
# '879950425588844557177426831791',
# '880369233375230345237001511006',
# '886180838786633773936677813818',
# '886430358468567310311007723004',
# '887916493746193939407481623391',
# '888021904600511420323095129935',
# '888517498954149177086283916722',
# '891182989185983545761655978623',
# '897705953598294772269569489281',
# '899082900417573006084750602123',
# '899353684702041035700102438716',
# '901103510796290218917651903823',
# '902763751470786794946912471631',
# '906824386019316813789030483695',
# '908741193082513651836950434578',
# '911801947447849749468305764840',
# '915736860556289509455669530049',
# '915986308688735366393353350740',
# '919002813906622793381125049416',
# '921287276013810837359841315530',
# '924939006160714533549353726515',
# '925679448263116681180549137562',
# '927075281189608119735911336961',
# '931660023131522836511470299550',
# '934701751347399243333120058853',
# '939103340398727679812199945201',
# '952440288393343800284327753087',
# '965523656856760127560055059644',
# '969325292841504805778529336047',
# '971476961920773226447199844576',
# '988068515766013782236551550185',
# '989440509183467842001314342301',
# '995561512722026805270815340218',
#]

class LIDCDataModule(pl.LightningDataModule):
    """PyTorch data module to load LIDC data"""

    def __init__(
        self,
        working_dir: str = "./working",
        augment_on_fly=True,
        fold=0,
        k_folds=5,
        batch_size=5,
        num_workers=4,
        **kwargs,
    ):
        super().__init__()
        self.working_dir = Path(working_dir)

        self.fold = fold
        self.k_folds = k_folds

        self.train_cases = []
        self.validation_cases = []
        self.test_cases = []

        self.augment_on_fly = augment_on_fly
        self.batch_size = batch_size
        self.num_workers = num_workers

        self.training_set = None
        self.validation_set = None
        self.test_set = None

        self.validation_data = []
        self.test_data = []

        self.num_observers = 4

        print(f"Training fold {self.fold}")

    @staticmethod
    def add_model_specific_args(parent_parser):
        """Add arguments used for Data module"""
        parser = parent_parser.add_argument_group("LIDC Data Loader")
        parser.add_argument("--augment_on_fly", type=bool, default=True)
        parser.add_argument("--fold", type=int, default=0)
        parser.add_argument("--k_folds", type=int, default=5)
        parser.add_argument("--batch_size", type=int, default=5)
        parser.add_argument("--num_workers", type=int, default=4)

        return parent_parser

    def setup(self, stage=None):

        cases = LIDC_PAT_IDS
        cases.sort()
        random.shuffle(cases)  # will be consistent for same value of 'seed everything'
        cases_per_fold = math.ceil(len(cases) / self.k_folds)

        for f in range(self.k_folds):

            if self.fold == f:
                val_test_cases = cases[f * cases_per_fold : (f + 1) * cases_per_fold]

                if len(val_test_cases) == 1:
                    self.validation_cases = val_test_cases
                else:
                    self.validation_cases = val_test_cases[: int(len(val_test_cases) / 2)]
                    # self.validation_cases = val_test_cases[: 5]
                    self.test_cases = val_test_cases[int(len(val_test_cases) / 2) :]
            else:
                self.train_cases += cases[f * cases_per_fold : (f + 1) * cases_per_fold]

        print(f"Training cases: {self.train_cases}")
        print(f"Validation cases: {self.validation_cases}")
        print(f"Testing cases: {self.test_cases}")

        augment_on_fly = self.augment_on_fly

        self.training_set = LIDCDataset(
            self.working_dir,
            augment_on_fly=augment_on_fly,
            case_ids=self.train_cases
        )
        print(f"Training Set Size: {len(self.training_set)}")
        self.validation_set = LIDCDataset(
            self.working_dir,
            augment_on_fly=False,
            case_ids=self.validation_cases
        )
        print(f"Validation Set Size: {len(self.validation_set)}")
        self.test_set = LIDCDataset(
            self.working_dir,
            augment_on_fly=False,
            case_ids=self.test_cases
        )

    def train_dataloader(self):
        return torch.utils.data.DataLoader(
            self.training_set,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
        )

    def val_dataloader(self):
        return torch.utils.data.DataLoader(
                self.validation_set,
                batch_sampler=torch.utils.data.BatchSampler(
                    ObserverSampler(self.validation_set, self.num_observers),
                    batch_size=self.num_observers,
                    drop_last=False,
                ),
                num_workers=self.num_workers,
            )


class ProbUNet(pl.LightningModule):
    def __init__(
        self,
        **kwargs,
    ):
        super().__init__()

        self.save_hyperparameters()

        loss_params = None

        if self.hparams.loss_type == "elbo":
            loss_params = {
                "beta": self.hparams.beta,
            }

        if self.hparams.loss_type == "geco":
            loss_params = {
                "kappa": self.hparams.kappa,
                "clamp_rec": self.hparams.clamp_rec,
                "clamp_contour": self.hparams.clamp_contour,
                "kappa_contour": self.hparams.kappa_contour,
            }

        loss_params["top_k_percentage"] = self.hparams.top_k_percentage
        loss_params["contour_loss_lambda_threshold"] = self.hparams.contour_loss_lambda_threshold
        loss_params["contour_loss_weight"] = self.hparams.contour_loss_weight

        if self.hparams.prob_type == "prob":
            self.prob_unet = ProbabilisticUnet(
                self.hparams.input_channels,
                2,
                self.hparams.filters_per_layer,
                self.hparams.latent_dim,
                self.hparams.no_convs_fcomb,
                self.hparams.loss_type,
                loss_params,
                2,
            )
        elif self.hparams.prob_type == "hierarchical":
            self.prob_unet = HierarchicalProbabilisticUnet(
                input_channels=self.hparams.input_channels,
                num_classes=2,
                filters_per_layer=self.hparams.filters_per_layer,
                down_channels_per_block=self.hparams.down_channels_per_block,
                latent_dims=[self.hparams.latent_dim] * (len(self.hparams.filters_per_layer) - 1),
                convs_per_block=self.hparams.convs_per_block,
                blocks_per_level=self.hparams.blocks_per_level,
                loss_type=self.hparams.loss_type,
                loss_params=loss_params,
                ndims=2,
            )

        self.validation_directory = None
        self.kl_div = None

    @staticmethod
    def add_model_specific_args(parent_parser):
        parser = parent_parser.add_argument_group("Probabilistic UNet")
        parser.add_argument("--prob_type", type=str, default="prob")
        parser.add_argument("--learning_rate", type=float, default=1e-5)
        parser.add_argument("--lr_lambda", type=float, default=0.99)
        parser.add_argument("--input_channels", type=int, default=1)
        parser.add_argument(
            "--filters_per_layer", nargs="+", type=int, default=[64 * (2 ** x) for x in range(5)]
        )
        parser.add_argument("--down_channels_per_block", nargs="+", type=int, default=None)
        parser.add_argument("--latent_dim", type=int, default=6)
        parser.add_argument("--no_convs_fcomb", type=int, default=4)
        parser.add_argument("--convs_per_block", type=int, default=2)
        parser.add_argument("--blocks_per_level", type=int, default=1)
        parser.add_argument("--loss_type", type=str, default="elbo")
        parser.add_argument("--beta", type=float, default=1.0)
        parser.add_argument("--kappa", type=float, default=0.02)
        parser.add_argument("--kappa_contour", type=float, default=None)
        parser.add_argument("--clamp_rec", nargs="+", type=float, default=[1e-5, 1e5])
        parser.add_argument("--clamp_contour", nargs="+", type=float, default=[1e-3, 1e3])
        parser.add_argument("--top_k_percentage", type=float, default=None)
        parser.add_argument("--contour_loss_lambda_threshold", type=float, default=None)
        parser.add_argument("--contour_loss_weight", type=float, default=0.0)  # no longer used
        parser.add_argument("--epochs_all_rec", type=int, default=0)  # no longer used

        return parent_parser

    def forward(self, x):
        self.prob_unet.forward(x, None, False)
        return x

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(), lr=self.hparams.learning_rate, weight_decay=0
        )

        scheduler = torch.optim.lr_scheduler.LambdaLR(
            optimizer, lr_lambda=[lambda epoch: self.hparams.lr_lambda ** (epoch)]
        )

        return [optimizer], [scheduler]

    def frange_cycle_linear(self, start, stop, n_epoch, n_cycle=4, ratio=0.5):
        L = np.ones(n_epoch)
        period = n_epoch/n_cycle
        step = (stop-start)/(period*ratio) # linear schedule
        for c in range(n_cycle):
            v , i = start , 0
            while v <= stop and (int(i+c*period) < n_epoch):
                L[int(i+c*period)] = v
                v += step
                i += 1
        return L

    def training_step(self, batch, _):

        x, y, m, _ = batch

        # Add background layer for one-hot encoding
        #y = torch.unsqueeze(y, dim=1)
        not_y = 1 - y.max(axis=1).values
        not_y = torch.unsqueeze(not_y, dim=1)
        y = torch.cat((not_y, y), dim=1).float()

        if self.hparams.prob_type == "prob":
            self.prob_unet.forward(x, y, training=True)
        else:
            self.prob_unet.forward(x, y)

        if self.hparams.prob_type == "prob":
            beta_vals = self.frange_cycle_linear(0.0, 0.01, 100, 4, 1.0)
#            loss = self.prob_unet.loss(y, mask=m, beta=beta_vals[self.current_epoch])
            loss = self.prob_unet.loss(y, mask=m)
        else:
            loss = self.prob_unet.loss(x, y, mask=m)

        training_loss = loss["loss"]

        if self.hparams.prob_type == "prob":
            reg_loss = (
                l2_regularisation(self.prob_unet.posterior)
                + l2_regularisation(self.prob_unet.prior)
                + l2_regularisation(self.prob_unet.fcomb.layers)
            )
            training_loss = training_loss + 1e-5 * reg_loss
        self.log(
            "training_loss",
            training_loss.detach(),
            on_step=True,
            on_epoch=False,
            prog_bar=True,
            logger=True,
        )

        self.kl_div = loss["kl_div"].detach().cpu()

        for k in loss:
            if k == "loss":
                continue
            self.log(
                k,
                loss[k].detach() if isinstance(loss[k], torch.Tensor) else loss[k],
                on_step=True,
                on_epoch=False,
                prog_bar=True,
                logger=True,
            )
        return training_loss

    def validation_step(self, batch, _):

        n = 4
        m = 4

        with torch.set_grad_enabled(False):
            x, y, _, info = batch

            # Image will be same for all in batch
            x = x[0, :, :, :].unsqueeze(0)
            vis = ImageVisualiser(sitk.GetImageFromArray(x.to("cpu")[0,:,:,:]), axis="z")
            x = x.repeat(m, 1, 1, 1)
            self.prob_unet.forward(x)

            py = self.prob_unet.sample(testing=True)
            py = py.to("cpu")
            # print(f"{pred_y[0,:,:,:].min()} {pred_y[0,:,:,:].max()}")
            # pred_y = torch.sigmoid(pred_y)
            # print(f"{pred_y[0,:,:,:].min()} {pred_y[0,:,:,:].max()}")

            # pred_y = pred_y[:,1,:,:] > 0.5
            # pred_y = pred_y.unsqueeze(1)
            pred_y = torch.zeros(py[:,0,:].shape).int()
            for b in range(py.shape[0]):
                pred_y[b] = py[b,:].argmax(0).int()

            y = y.squeeze(1)
            y = y.to("cpu")

            # Intersection over Union (also known as Jaccard Index)
            jaccard = JaccardIndex(num_classes=2)
            term_1 = 0
            for i in range(n):
                for j in range(m):
                    if pred_y[i].sum() + y[j].sum() == 0:
                        continue
                    iou = jaccard(pred_y[i], y[j])
                    term_1 += 1 - iou
            term_1 = term_1 * (2/(m*n))

            term_2 = 0
            for i in range(n):
                for j in range(n):
                    if pred_y[i].sum() + pred_y[j].sum() == 0:
                        continue
                    iou = jaccard(pred_y[i], pred_y[j])
                    term_2 += 1 - iou
            term_2 = term_2 * (1/(n*n))

            term_3 = 0
            for i in range(m):
                for j in range(m):
                    if y[i].sum() + y[j].sum() == 0:
                        continue
                    iou = jaccard(y[i], y[j])
                    term_3 += 1 - iou
            term_3 = term_3 * (1/(m*m))

            D_ged = term_1 - term_2 - term_3

            contours = {}
            for o in range(n):
                obs_y = y[o].float()
                obs_y = obs_y.unsqueeze(0)
                contours[f"obs_{o}"] = sitk.GetImageFromArray(obs_y)
            for mm in range(m):
                samp_pred = pred_y[mm].float()
                samp_pred = samp_pred.unsqueeze(0)
                contours[f"sample_{mm}"] = sitk.GetImageFromArray(samp_pred)

            vis.add_contour(contours, colormap=plt.cm.get_cmap("cool"))
            vis.show()

            figure_path = "valid.png"
            plt.savefig(figure_path, dpi=300)
            plt.close("all")

            try:
                self.logger.experiment.log_image(figure_path)
            except AttributeError:
                # Likely offline mode
                pass

        self.log("GED", D_ged)
        return D_ged


def main(args, config_json_path=None):

    pl.seed_everything(args.seed, workers=True)

    args.working_dir = Path(args.working_dir)
    args.working_dir = args.working_dir.joinpath(args.experiment)
    # args.default_root_dir = str(args.working_dir)
    args.fold_dir = args.working_dir.joinpath(f"fold_{args.fold}")
    args.default_root_dir = str(args.fold_dir)

    comet_api_key = None
    comet_workspace = None
    comet_project = None

    if args.comet_api_key:
        comet_api_key = args.comet_api_key
        comet_workspace = args.comet_workspace
        comet_project = args.comet_project

    if comet_api_key is None:
        if "COMET_API_KEY" in os.environ:
            comet_api_key = os.environ["COMET_API_KEY"]
        if "COMET_WORKSPACE" in os.environ:
            comet_workspace = os.environ["COMET_WORKSPACE"]
        if "COMET_PROJECT" in os.environ:
            comet_project = os.environ["COMET_PROJECT"]

    if comet_api_key is not None:
        comet_logger = CometLogger(
            api_key=comet_api_key,
            workspace=comet_workspace,
            project_name=comet_project,
            experiment_name=args.experiment,
            save_dir=args.working_dir,
            offline=args.offline,
        )
        if config_json_path:
            comet_logger.experiment.log_code(config_json_path)

    dict_args = vars(args)

    data_module = LIDCDataModule(**dict_args)

    prob_unet = ProbUNet(**dict_args)

    if args.resume_from is not None:
        trainer = pl.Trainer(resume_from_checkpoint=args.resume_from)
    else:
        trainer = pl.Trainer.from_argparse_args(args)

    if comet_api_key is not None:
        trainer.logger = comet_logger

    lr_monitor = LearningRateMonitor(logging_interval="step")
    trainer.callbacks.append(lr_monitor)

    # Save the best model
    checkpoint_callback = ModelCheckpoint(
        monitor="GED",
        dirpath=args.default_root_dir,
        filename="probunet-{epoch:02d}-{GED:.2f}",
        save_top_k=1,
        mode="min",
    )
    trainer.callbacks.append(checkpoint_callback)

    trainer.fit(prob_unet, data_module)


if __name__ == "__main__":

    args = None
    config_json_path = None
    if len(sys.argv) == 2:
        # Check if JSON file parsed, if so read arguments from there...
        if sys.argv[-1].endswith(".json"):
            config_json_path = sys.argv[-1]
            with open(config_json_path, "r") as f:
                params = json.load(f)
                args = []
                for key in params:
                    args.append(f"--{key}")

                    if isinstance(params[key], list):
                        for list_val in params[key]:
                            args.append(str(list_val))
                    else:
                        args.append(str(params[key]))

    arg_parser = ArgumentParser()
    arg_parser = ProbUNet.add_model_specific_args(arg_parser)
    arg_parser = LIDCDataModule.add_model_specific_args(arg_parser)
    arg_parser = pl.Trainer.add_argparse_args(arg_parser)
    arg_parser.add_argument(
        "--config", type=str, default=None, help="JSON file with parameters to load"
    )
    arg_parser.add_argument("--seed", type=int, default=42, help="an integer to use as seed")
    arg_parser.add_argument("--experiment", type=str, default="lidc", help="Name of experiment")
    arg_parser.add_argument("--working_dir", type=str, default="./working")
    arg_parser.add_argument("--offline", type=bool, default=False)
    arg_parser.add_argument("--comet_api_key", type=str, default=None)
    arg_parser.add_argument("--comet_workspace", type=str, default=None)
    arg_parser.add_argument("--comet_project", type=str, default=None)
    arg_parser.add_argument("--resume_from", type=str, default=None)

    main(arg_parser.parse_args(args), config_json_path=config_json_path)
